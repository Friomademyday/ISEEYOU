<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Synthetix OS - Facial Tracking</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            background-color: #0a0a0c;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            overflow: hidden;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        #ui-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .robot-head {
            position: relative;
            width: 320px;
            height: 400px;
            background: linear-gradient(145deg, #2c2c2e, #1a1a1c);
            border-radius: 120px 120px 180px 180px;
            box-shadow: 0 20px 50px rgba(0,0,0,0.8), inset 0 0 20px rgba(255,255,255,0.05);
            border: 2px solid #3a3a3c;
        }

        .eye-socket {
            position: absolute;
            top: 130px;
            width: 90px;
            height: 60px;
            background: #050505;
            border-radius: 50%;
            border: 3px solid #1f1f21;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            box-shadow: inset 0 0 15px #000;
        }

        .eye-left {
            left: 45px;
        }

        .eye-right {
            right: 45px;
        }

        .pupil {
            width: 35px;
            height: 35px;
            background: radial-gradient(circle, #00f2ff 0%, #0051ff 70%, #001a4d 100%);
            border-radius: 50%;
            position: relative;
            transition: transform 0.1s ease-out;
            box-shadow: 0 0 15px rgba(0, 242, 255, 0.6);
        }

        .pupil::after {
            content: '';
            position: absolute;
            top: 20%;
            left: 20%;
            width: 8px;
            height: 8px;
            background: white;
            border-radius: 50%;
            opacity: 0.8;
        }

        .face-plates {
            position: absolute;
            bottom: 60px;
            width: 200px;
            height: 100px;
            left: 60px;
            border-top: 2px solid #333;
            border-radius: 40%;
        }

        #video-feedback {
            position: fixed;
            bottom: 20px;
            right: 20px;
            width: 150px;
            border: 2px solid #00f2ff;
            border-radius: 8px;
            transform: scaleX(-1);
        }

        .status-panel {
            color: #00f2ff;
            margin-top: 30px;
            text-transform: uppercase;
            letter-spacing: 2px;
            font-size: 12px;
            text-shadow: 0 0 10px rgba(0, 242, 255, 0.5);
        }

        .scan-line {
            position: absolute;
            width: 100%;
            height: 2px;
            background: rgba(0, 242, 255, 0.2);
            top: 0;
            animation: scan 4s linear infinite;
        }

        @keyframes scan {
            0% { top: 0; }
            100% { top: 100%; }
        }
    </style>
</head>
<body>

<div id="ui-container">
    <div class="robot-head">
        <div class="scan-line"></div>
        <div class="eye-socket eye-left">
            <div id="pupil-l" class="pupil"></div>
        </div>
        <div class="eye-socket eye-right">
            <div id="pupil-r" class="pupil"></div>
        </div>
        <div class="face-plates"></div>
    </div>
    <div class="status-panel" id="status">Initializing Neural Link...</div>
</div>

<video id="video-feedback" autoplay playsinline></video>

<script>
    const videoElement = document.getElementById('video-feedback');
    const statusText = document.getElementById('status');
    const pupilL = document.getElementById('pupil-l');
    const pupilR = document.getElementById('pupil-r');

    function onResults(results) {
        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
            statusText.innerText = "Subject Tracked";
            const landmarks = results.multiFaceLandmarks[0];
            
            const noseTip = landmarks[1];
            
            const x = (noseTip.x - 0.5) * 60;
            const y = (noseTip.y - 0.5) * 40;

            const moveX = -x;
            const moveY = y;

            pupilL.style.transform = `translate(${moveX}px, ${moveY}px)`;
            pupilR.style.transform = `translate(${moveX}px, ${moveY}px)`;
        } else {
            statusText.innerText = "Searching for Subject...";
            pupilL.style.transform = `translate(0px, 0px)`;
            pupilR.style.transform = `translate(0px, 0px)`;
        }
    }

    const faceMesh = new FaceMesh({
        locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
        }
    });

    faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
    });

    faceMesh.onResults(onResults);

    async function setupCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: {
                width: 640,
                height: 480
            }
        });
        videoElement.srcObject = stream;
        
        videoElement.onloadedmetadata = () => {
            sendFrames();
        };
    }

    async function sendFrames() {
        await faceMesh.send({image: videoElement});
        requestAnimationFrame(sendFrames);
    }

    setupCamera().catch(err => {
        statusText.innerText = "Optical Input Denied";
        console.error(err);
    });
</script>

</body>
  </html>
